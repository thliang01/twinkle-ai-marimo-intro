# /// script
# requires-python = ">=3.12"
# dependencies = [
#     "marimo",
#     "watchdog",
#     "openai==1.102.0",
#     "python-dotenv==1.1.1",
#     "datasets",
#     "pyarrow",
#     "pydantic==2.11.7",
# ]
# ///

import marimo

__generated_with = "0.18.4"
app = marimo.App()


@app.cell(hide_code=True)
def _(mo):
    mo.md(r"""
    <div style="background-color: #f0f8ff; border: 2px solid #4682b4; border-radius: 8px; padding: 12px; margin-bottom: 20px;">
        <p style="margin: 0; font-size: 14px; color: #2c5282;">
            â„¹ï¸ <strong>Fork Notice:</strong> This is a fork version adapted for molab/marimo from the original repository:
            <a href="https://github.com/ai-twinkle/llm-lab" target="_blank" style="color: #2c5282; text-decoration: underline;">https://github.com/ai-twinkle/llm-lab</a>
        </p>
    </div>
    """)
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(r"""
    # 01 - å°è©±è³‡æ–™ç”Ÿæˆ & å°è©±é›†æ ¼å¼ä»‹ç´¹
    <div align="left" style="line-height: 1;">
      <a href="https://discord.gg/Cx737yw4ed" target="_blank" style="margin: 2px;">
        <img alt="Discord" src="https://img.shields.io/badge/Discord-Twinkle%20AI-7289da?logo=discord&logoColor=white&color=7289da" style="display: inline-block; vertical-align: middle;"/>
      </a>
      <a href="https://huggingface.co/twinkle-ai" target="_blank" style="margin: 2px;">
        <img alt="Hugging Face" src="https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Twinkle%20AI-ffc107?color=ffc107&logoColor=white" style="display: inline-block; vertical-align: middle;"/>
      </a>
      <a href="https://github.com/ai-twinkle" target="_blank" style="margin: 2px;">
        <img alt="GitHub" src="https://img.shields.io/badge/GitHub-ai--twinkle-181717?logo=github&logoColor=white&color=181717" style="display: inline-block; vertical-align: middle;"/>
      </a>
      <a href="https://colab.research.google.com/github/ai-twinkle/llm-lab/blob/main/courses/2025-08-llm-dialogue-dataset/01_generate_dialogs.ipynb" target="_blank" style="margin: 2px;">
        <img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open 00_setup_and_api_call In Colab" style="display: inline-block; vertical-align: middle;"/>
      </a>
      <a href="https://molab.marimo.io/notebooks/nb_zNsH5TyPTT6sjhDdVvw2Nx" target="_blank" style="margin: 2px;">
            <img src="https://molab.marimo.io/molab-shield.png" alt="Open in molab" style="display: inline-block; vertical-align: middle;"/>
      </a>
    </div>

    åœ¨é€™å€‹ Labï¼Œæˆ‘å€‘çš„ç›®æ¨™æ˜¯å»ºç«‹ä¸€ä»½ã€Œå¯æŒçºŒæ“´å……ã€çš„å°è©±è³‡æ–™é›†ã€‚ä¸»è¦çš„æ­¥é©Ÿå¦‚ä¸‹ï¼š

    1. é€£æ¥ `Gemma-3-27B-it-fast` APIï¼ˆä½¿ç”¨ OpenAI SDKï¼‰
    2. ä»‹ç´¹å°è©±è³‡æ–™çš„å¸¸è¦‹æ ¼å¼ï¼š**Alpaca**, **ShareGPT**ï¼Œä»¥åŠ **OpenAI** æ ¼å¼ï¼ˆæˆ‘å€‘æ¡ç”¨å¾Œè€…ï¼‰
    3. æ¢è¨ `.jsonl` æ ¼å¼èˆ‡ `.parquet` æ ¼å¼çš„å„ªç¼ºé»ï¼Œä¸¦èªªæ˜ HF Hub å° parquet çš„è½‰æ›æ”¯æ´
       (ä¸Šå‚³ parquet æ™‚ HF æœƒè‡ªå‹•ç”Ÿæˆ `.parquet` åˆ†æ”¯èˆ‡ viewer)
    """)
    return


@app.cell
def _():
    import os
    from openai import OpenAI
    from dotenv import load_dotenv

    # è¼‰å…¥ .env æª”æ¡ˆä¸­çš„ç’°å¢ƒè®Šæ•¸
    load_dotenv()

    # å¾ç’°å¢ƒè®Šæ•¸å–å¾— API Key
    API_KEY = os.getenv('NEBIUS_API_KEY')
    BASE_URL = "https://api.studio.nebius.ai/v1"
    MODEL = "google/gemma-3-27b-it-fast"

    # é©—è­‰ API Key æ˜¯å¦å­˜åœ¨
    if not API_KEY:
        print("âŒ éŒ¯èª¤ï¼šæ‰¾ä¸åˆ° NEBIUS_API_KEY ç’°å¢ƒè®Šæ•¸")
        print("è«‹ç¢ºä¿ï¼š")
        print("1. å·²å»ºç«‹ .env æª”æ¡ˆ")
        print("2. å‰å¾€ https://studio.nebius.ai è¨»å†Šä¸¦å–å¾— API Key")
        print("3. åœ¨ .env æª”æ¡ˆä¸­è¨­å®š NEBIUS_API_KEY=ä½ çš„APIé‡‘é‘°")
        raise ValueError("API Key æœªè¨­å®š")
    else:
        print(f"âœ… æˆåŠŸè¼‰å…¥ API Key (å‰ 8 å­—å…ƒ: {API_KEY[:8]}...)")

    # åˆå§‹åŒ– API client
    client = OpenAI(
        api_key=API_KEY,
        base_url=BASE_URL  # BASE_URL å·²åŒ…å« /v1
    )

    print("âœ… API client å·²åˆå§‹åŒ–")
    return MODEL, client


@app.cell(hide_code=True)
def _(mo):
    mo.md(r"""
    ## å¸¸è¦‹å°è©±è³‡æ–™é›†æ ¼å¼æ¯”è¼ƒ

    - **Alpaca**ï¼šå–®è¼ªæŒ‡ä»¤ + å›ç­”æ ¼å¼ï¼Œé€šå¸¸æ˜¯ Instruct tuningã€‚ï¼ˆä¸é©åˆå¤šè¼ªå ´æ™¯ï¼‰
    - **ShareGPT**ï¼šä½¿ç”¨ä»¥ä¸‹æ ¼å¼ï¼Œæ”¯æ´å¤šè§’è‰²å¤šè¼ªå°è©±
    ```json
    {
        "conversations":[
            {"from":"human","value":"..."},
            {"from":"gpt","value":"..."}â€¦]
    }
    ```
    - **OpenAI Chat Messages**ï¼šæœ€å¸¸ç”¨æ ¼å¼ï¼Œåƒé€™æ¨£ï¼š
    ```json
    {
      "messages":[
          {"role":"system","content":"..."},
          {"role":"user","content":"..."},
          {"role":"assistant","content":"..."}]
    }
    ```
    Hugging Face èˆ‡å¤šæ•¸å·¥å…·éƒ½æ”¯æ´é€™ç¨®æ ¼å¼ï¼Œä¸” OpenAI æœ¬è³ªä¸Šæ˜¯ ShareGPT æ ¼å¼çš„è®Šé«”

    æˆ‘å€‘å°‡æ¡ç”¨ **OpenAI messages** æ ¼å¼ï¼Œä¸¦ä½¿ç”¨ `.jsonl` å„²å­˜ï¼›

    å¦å¤–ï¼Œé‚„æœ‰ä¸€ç¨®å« `.parquet` æ ¼å¼ï¼Œä»–çš„å„ªå‹¢ä¾‹å¦‚ï¼š

    - é«˜æ•ˆå£“ç¸®ã€æ”¯æ´åˆ†æ¬„è®€å–ã€å¤§æª”æ¡ˆæ“ä½œå¿«é€Ÿ
    - HF Hub æ”¯æ´ç›´æ¥ä¸Šå‚³ parquetï¼Œä¹Ÿæœƒè‡ªå‹•ç”Ÿæˆå¯å…¬é–‹ç€è¦½ç‰ˆæœ¬
    """)
    return


@app.cell
def _(mo):
    mo.image(
        src="assets/01_wiki_data_format.png",
        alt="åœ– 1ï¼šWiki å°è©±æ ¼å¼ç¤ºæ„åœ–",
        rounded=True,
        caption="åœ– 1ï¼šWiki å°è©±æ ¼å¼ç¤ºæ„åœ–",
    )
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(r"""
    ## JSONL vs Parquet æ¯”è¼ƒ

    | æ ¼å¼     | å„ªé»                          | ç¼ºé»                         |
    |----------|-------------------------------|------------------------------|
    | `.jsonl` | æ˜“è®€ã€è¼•é‡ã€é–‹ç™¼å‹å–„              | æª”æ¡ˆå¤§ã€å¤§é‡æ•¸æ“šè®€å–æ•ˆç‡è¼ƒä½   |
    | `.parquet` | å£“ç¸®æ•ˆæœå¥½ã€æŸ¥è©¢æ•ˆèƒ½é«˜ã€æ”¯æ´ HF è½‰æ› | ä¸æ˜“ç›´æ¥é–±è®€ï¼Œéœ€ä½¿ç”¨å·¥å…·è™•ç†   |

    æ³¨æ„ï¼šå³ä½¿ä½ ä¸Šå‚³ `.jsonl`ï¼ŒHF Hub ä¹Ÿå¯èƒ½å¹«ä½ ç”Ÿæˆ `.parquet` åˆ†æ”¯ï¼Œæ–¹ä¾¿ç€è¦½èˆ‡è¼‰å…¥ã€‚
    """)
    return


@app.cell
def _(mo):
    mo.image(
        src="assets/01_hf_parquet_branch.png",
        alt="åœ– 2ï¼šHF Hub è‡ªå‹•ç”Ÿæˆçš„ .parquet åˆ†æ”¯",
        rounded=True,
        caption="åœ– 2ï¼šHF Hub è‡ªå‹•ç”Ÿæˆçš„ .parquet åˆ†æ”¯",
    )
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(r"""
    ## Reference-Free vs Reference-Based

    - **Reference-Freeï¼ˆç„¡åƒè€ƒï¼‰**ï¼šç”¨ä¸€äº› seed prompt å¼•å°æ¨¡å‹ç”Ÿæˆã€‚æœ€æ—©å‡ºè‡ª [Self-Instruct: Aligning Language Models with Self-Generated Instructions
    ](https://arxiv.org/abs/2212.10560)ã€‚
    - **Reference-Basedï¼ˆåƒè€ƒå…§å®¹ï¼‰**ï¼šä½¿ç”¨çœŸå¯¦è³‡æ–™ç‰‡æ®µï¼ˆä¾‹å¦‚ Wiki æ¢ç›®ï¼‰ä½œ prompt ä½æ–™ï¼Œè®“ç”Ÿæˆå…§å®¹æ›´ groundedã€‚
    """)
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(r"""
    ### Reference-Free å¯¦ä½œ

    åœ¨ Reference-Free çš„æƒ…å¢ƒä¸‹ï¼Œæˆ‘å€‘ä¸¦ä¸ä¾è³´ä»»ä½•å¤–éƒ¨çŸ¥è­˜åº«æˆ–æ–‡ä»¶ï¼Œè€Œæ˜¯é€é **seed ä»»å‹™ (seed task)** ä¾†é©…å‹•æ¨¡å‹è‡ªè¡Œç”Ÿæˆè³‡æ–™ã€‚
    é€™äº› seed ä»»å‹™é€šå¸¸åŒ…å«ä¸€å€‹ **instructionï¼ˆæŒ‡ä»¤ï¼‰**ï¼ŒåŠ ä¸Šå°‘é‡çš„ **instanceï¼ˆç¯„ä¾‹è¼¸å…¥/è¼¸å‡ºå°ï¼‰**ï¼Œä½œç‚ºæ¨¡å‹æ¨¡ä»¿èˆ‡å»¶ä¼¸çš„èµ·é»ã€‚

    é€™ç¨®æ–¹æ³•çš„ä»£è¡¨æ€§å·¥ä½œæ˜¯ *Self-Instruct*ï¼Œå®ƒé€éäººå·¥è¨­è¨ˆçš„ä¸€äº›é«˜å“è³ªç¨®å­æŒ‡ä»¤ï¼Œè®“æ¨¡å‹å»ã€Œèˆ‰ä¸€åä¸‰ã€ç”¢ç”Ÿæ›´å¤šæŒ‡ä»¤å’Œå°æ‡‰ç­”æ¡ˆï¼Œæœ€çµ‚å»ºç«‹å‡ºé¾å¤§çš„è³‡æ–™é›†ã€‚

    ä»¥ä¸‹æ˜¯ä¸€å€‹å–è‡ª [self-instruct](https://github.com/yizhongw/self-instruct/blob/main/data/seed_tasks.jsonl) seed ç¯„ä¾‹ï¼Œä¸»é¡Œæ˜¯ã€Œæ—©é¤å»ºè­°ã€ã€‚

    ```json
    {
      "id": "seed_task_0",
      "name": "breakfast_suggestion",
      "instruction": "Is there anything I can eat for a breakfast that doesn't include eggs, yet includes protein, and has roughly 700-1000 calories?",
      "instances": [
        {
          "input": "\",
          "output": "Yes, you can have 1 oatmeal banana protein shake and 4 strips of bacon. The oatmeal banana protein shake may contain 1/2 cup oatmeal, 60 grams whey protein powder, 1/2 medium banana, 1 tbsp flaxseed oil and 1/2 cup water, totaling about 550 calories. The 4 strips of bacon contains about 200 calories."
        }
      ],
      "is_classification": false
    }
    ```

    èªªæ˜ï¼š

    - idï¼šä»»å‹™çš„å”¯ä¸€è­˜åˆ¥ç¢¼ã€‚
    - nameï¼šä»»å‹™åç¨±ï¼Œæ–¹ä¾¿è¾¨è­˜ã€‚
    - instructionï¼šçµ¦æ¨¡å‹çš„ä¸»è¦å•é¡Œæˆ–æŒ‡ä»¤ã€‚
    - instancesï¼šåŒ…å«è¼¸å…¥/è¼¸å‡ºå°ï¼Œæœ¬ä¾‹ä¸­ input ç‚ºç©ºï¼Œä»£è¡¨æ¨¡å‹ç›´æ¥ä¾ instruction å›ç­”ï¼›output æ˜¯ä¸€å€‹å¯èƒ½çš„è§£ç­”ã€‚
    - is_classificationï¼šæ¨™è¨˜æ­¤ä»»å‹™æ˜¯å¦ç‚ºåˆ†é¡å‹å•é¡Œï¼ˆæ­¤ä¾‹ç‚ºå¦ï¼‰ã€‚
    """)
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(r"""
    åœ¨å¯¦å‹™ä¸­ï¼Œæˆ‘å€‘æœƒè¨­è¨ˆæ•¸ååˆ°æ•¸ç™¾å€‹ seed ä»»å‹™ï¼Œæ¶µè“‹ä¸åŒé ˜åŸŸèˆ‡æŒ‡ä»¤å‹æ…‹ï¼Œä½œç‚º Reference-Free è³‡æ–™ç”Ÿæˆçš„æ ¸å¿ƒåŸºç¤ã€‚

    ä¸éï¼Œæˆ‘å€‘çš„ä½œæ³•ä¸¦**ä¸å®Œå…¨ç­‰åŒæ–¼ Self-Instruct**ã€‚
    ç›¸è¼ƒæ–¼ Self-Instruct çš„å®Œæ•´ pipelineï¼ˆå¦‚ï¼šéæ¿¾ã€å»é‡ã€è¿­ä»£æ“´å±•ï¼‰ï¼Œæˆ‘å€‘å‚¾å‘æ¡ç”¨æ›´ç°¡å–®ç›´æ¥çš„æ–¹å¼ï¼š

    1.	äººå·¥æ’°å¯«å°‘é‡é«˜å“è³ª seed æŒ‡ä»¤ã€‚
    2.	è¦æ±‚æ¨¡å‹åŸºæ–¼é€™äº› seed ç”¢ç”Ÿæ–°çš„ seed æŒ‡ä»¤ï¼ˆä½†åƒ…é™è¼¸å‡º seed æœ¬æ–‡ï¼Œé¿å…é›œè¨Šï¼‰ã€‚
    3.	å†åˆ©ç”¨é€™äº›æ–° seed æŒ‡ä»¤ï¼Œç”±æ¨¡å‹ç”Ÿæˆå–®è¼ªå•ç­”é…å°ã€‚

    é€™æ¨£çš„æµç¨‹æ›´è¼•é‡ï¼Œé›–ç„¶ç¼ºå°‘è¤‡é›œçš„ç¯©é¸èˆ‡å¤šè¼ªè¿­ä»£ï¼Œä½†å°æ–¼èª²ç¨‹å¯¦ä½œèˆ‡æ•™å­¸ç›®æ¨™è€Œè¨€ï¼Œå·²ç¶“èƒ½æ¸…æ¥šå±•ç¾ Reference-Free çš„æ ¸å¿ƒç²¾ç¥ã€‚
    """)
    return


@app.cell
def _(MODEL, client):
    import re

    base_seed = "Is there anything I can eat for a breakfast that doesn't include eggs, yet includes protein, and has roughly 700-1000 calories?"

    seed_gen_messages = [
        {'role': 'system', 'content': 'ä½ æ˜¯ä¸€å€‹è³‡æ–™ç”Ÿæˆå™¨ã€‚ä½ çš„ä»»å‹™æ˜¯ã€æ ¹æ“šçµ¦å®š seedï¼Œç”¢ç”Ÿä¸€å‰‡ä¸åŒä½†ä¸»é¡Œç›¸é—œçš„ seed æŒ‡ä»¤ã€ã€‚\nå‹™å¿…éµå®ˆï¼š\n1) åƒ…è¼¸å‡ºæ–°çš„ seed æŒ‡ä»¤æœ¬èº«ï¼ˆç¹é«”ä¸­æ–‡ï¼‰ã€‚\n2) ä¸è¦åŠ ä»»ä½•è§£é‡‹ã€å‰å¾Œæ–‡ã€å¼•è™Ÿã€æ¨™é»è£é£¾æˆ–æ¨™ç±¤ã€‚\n3) ä¸€è‡³å…©å¥è©±ï¼Œæ¸…æ¥šå¯åŸ·è¡Œã€‚\n4) é¿å…é‡è¤‡èˆ‡åŸ seed å®Œå…¨ç›¸åŒçš„é™åˆ¶æ¢ä»¶æˆ–æªè¾­ï¼Œä½†ä¸»é¡Œéœ€ç›¸é—œã€‚\n'}, 
        {'role': 'user', 'content': f'é€™æ˜¯åŸå§‹ seedï¼š\n{base_seed}\n\nè«‹ä¾è¦å‰‡ç”¢ç”Ÿä¸€å€‹æ–°çš„ seed æŒ‡ä»¤ï¼ˆç¹é«”ä¸­æ–‡ï¼‰ã€‚åªè¼¸å‡ºæ–° seed æœ¬æ–‡ï¼Œå…¶ä»–ä¸€å¾‹ä¸è¦ã€‚'}
    ]

    try:
        resp_seed = client.chat.completions.create(
            model=MODEL, 
            messages=seed_gen_messages, 
            temperature=0.9, 
            max_tokens=200
        )
        new_seed_instruction_raw = resp_seed.choices[0].message.content.strip()

        def sanitize_seed(text: str) -> str:
            text = text.strip()
            text = re.sub(r'^```.*?\n|\n```$', '', text, flags=re.MULTILINE)
            return text

        new_seed_instruction = sanitize_seed(new_seed_instruction_raw)
        print('ğŸ”¹ åŸå§‹ seedï¼š', base_seed)
        print('ğŸ”¸ æ–°çš„ seedï¼š', new_seed_instruction)

    except Exception as e:
        print(f"âŒ ç”Ÿæˆæ–° seed æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{str(e)}")
        print("è«‹æª¢æŸ¥ API Key å’Œç¶²è·¯é€£æ¥")
        raise e
    return new_seed_instruction, re


@app.cell
def _(MODEL, client, new_seed_instruction):
    # Step 2: ä»¥ã€Œæ–°çš„ seed æŒ‡ä»¤ã€ç•¶ä½œ user æå•ï¼Œç”Ÿæˆå–®è¼ªå›ç­”ï¼ˆassistant ä¸€æ¬¡å›è¦†ï¼‰ã€‚
    # ç”¢å‡ºç‚º OpenAI messages æ ¼å¼ï¼Œå¯ç›´æ¥ç´¯ç©é€² datasets.jsonlã€‚

    import json
    from uuid import uuid4
    from pathlib import Path

    qa_messages = [
        {"role": "system", "content": "ä½ æ˜¯ä¸€ä½ç‡Ÿé¤Šèˆ‡é£²é£Ÿè¦åŠƒçš„å°ˆå®¶ï¼Œè«‹ä½¿ç”¨ç¹é«”ä¸­æ–‡ï¼Œçµ¦å‡ºæ˜ç¢ºã€å¯åŸ·è¡Œçš„å»ºè­°ã€‚"},
        {"role": "user", "content": new_seed_instruction},
    ]

    try:
        resp_qa = client.chat.completions.create(
            model=MODEL,
            messages=qa_messages,
            temperature=0.7,
            max_tokens=600,
        )

        answer = resp_qa.choices[0].message.content

        example = {
            "id": str(uuid4()),
            "type": "reference_free",
            "seed": new_seed_instruction,
            "messages": [
                qa_messages[0],                 # system
                qa_messages[1],                 # userï¼ˆæ–°çš„ seedï¼‰
                {"role": "assistant", "content": answer},  # å–®è¼ªå›ç­”
            ]
        }

        # âœ… å¯é¸ï¼šè¿½åŠ å¯«å…¥ datasets.jsonlï¼ˆä¾›ä¸‹ä¸€ç« ç¯€ QC ä½¿ç”¨ï¼‰
        out_path = Path("outputs/datasets.jsonl")
        out_path.parent.mkdir(parents=True, exist_ok=True)

        with out_path.open("a", encoding="utf-8") as f:
            f.write(json.dumps(example, ensure_ascii=False) + "\n")

        print("âœ… å·²ç”Ÿæˆå–®è¼ª QA ä¸¦å¯«å…¥ï¼š", out_path)
        print("\n=== å›ç­”é è¦½ ===\n", answer[:800])

    except Exception as e:
        print(f"âŒ ç”Ÿæˆ QA å°è©±æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{str(e)}")
        print("è«‹æª¢æŸ¥ API Key å’Œç¶²è·¯é€£æ¥")
        raise e
    return Path, json, uuid4


@app.cell(hide_code=True)
def _(mo):
    mo.md(r"""
    ## Reference-based è³‡æ–™ç”Ÿæˆ

    åœ¨ Reference-based çš„æƒ…å¢ƒä¸‹ï¼Œæˆ‘å€‘æœƒä½¿ç”¨ä¸€æ®µå¤–éƒ¨æ–‡æœ¬ä½œç‚ºä¾æ“šï¼Œä¸¦åœ¨å…¶ä¸Šç”Ÿæˆå•ç­”è³‡æ–™ã€‚
    é€™ç¨®æ–¹å¼å¸¸è¦‹æ–¼çŸ¥è­˜å‹ QA ç³»çµ±ï¼ˆä¾‹å¦‚ Wikipedia å•ç­”ï¼‰ï¼Œå…¶æ ¸å¿ƒåŸå‰‡æ˜¯ï¼š

    - å•é¡Œï¼ˆQuestionï¼‰å¿…é ˆä¾†è‡ªæ–¼æ–‡æœ¬
    - ç­”æ¡ˆï¼ˆAnswerï¼‰å¿…é ˆå®Œå…¨ä¾ç…§æ–‡æœ¬ï¼Œä¸å¯è¶…å‡ºæ–‡æœ¬ç¯„åœ

    é€™æ¨£ç”Ÿæˆçš„è³‡æ–™ï¼Œå¯ä»¥å¹«åŠ©æ¨¡å‹å­¸æœƒã€Œæ ¹æ“šåƒè€ƒå…§å®¹å›ç­”ã€ï¼Œè€Œéæ†‘ç©ºæƒ³åƒã€‚
    """)
    return


@app.cell
def _():
    # æˆ‘å€‘é€™è£¡ç›´æ¥ç¤ºç¯„ä¸€æ®µ Wikipedia ä¸­æ–‡æ¢ç›®ï¼ˆå–è‡ªå…¬é–‹è³‡æ–™é›† https://huggingface.co/datasets/lianghsun/wikipedia-zh-742Mï¼‰
    # https://twbsball.dils.tku.edu.tw/wiki/index.php?title=%E9%A6%96%E9%A0%81
    # https://twbsball.dils.tku.edu.tw/wiki/index.php?title=å…„å¼Ÿè±¡éšŠ
    # https://twbsball.dils.tku.edu.tw/wiki/index.php?title=å…„å¼Ÿé£¯åº—æ£’çƒéšŠ
    # https://twbsball.dils.tku.edu.tw/wiki/index.php?title=å…„å¼Ÿè±¡éšŠéšŠå²
    wiki_context = """
    å…¨å£˜æ‰“æ¢…èŠ±
    ã€€ã€€è·æ£’ä¸‰å¹´ï¼ˆ1992å¹´ï¼‰é–‹å§‹ï¼Œç•¶æ™‚çš„ç¸½æ•™ç·´æ£®ä¸‹æ­£å¤«ç‚ºäº†æ¿€å‹µçƒå“¡å£«æ°£ï¼Œç‡å…ˆæå‡ºçƒå“¡æ¯æ“Šå‡ºä¸€æ”¯å…¨å£˜æ‰“ï¼Œå°±è²¼ä¸Šä¸€æšé»ƒè‰²çš„æ¢…èŠ±æ¨™èªŒçš„éšŠå¾½åœ¨æ‰“æ“Šé ­ç›”ä¸Šçš„åšæ³•ï¼Œæ„å¤–æ”¶åˆ°ä¸éŒ¯çš„æ•ˆæœï¼Œä¸ä½†æœ‰æ•ˆæ¿€å‹µäº†çƒå“¡çš„å£«æ°£ï¼Œè€Œä¸”é‚„å¼•ç™¼çƒå“¡é–“å°æ–¼å…¨å£˜æ‰“åŠã€Œæ”¶é›†æ¢…èŠ±ã€çš„è‰¯æ€§ç«¶çˆ­ï¼Œå› è€Œæ‹¿ä¸‹äº†è·æ£’ä¸‰å¹´çš„ç¸½å† è»ï¼›æ­¤å¾Œï¼Œé€™æ¨£çš„åšæ³•å°±æˆç‚ºäº†å…„å¼Ÿçš„å‚³çµ±ã€‚

    ã€€ã€€è·æ£’åå››å¹´ï¼ˆ2003å¹´ï¼‰æ™‚ï¼Œæœ‰æŸå®¶è´ŠåŠ©å•†æ‰“ç®—ä»¥è©²å…¬å¸çš„æ¨™èªŒä»£æ›¿å…¨å£˜æ‰“çš„å°éšŠå¾½ï¼Œå»æ„å¤–é­åˆ°è¨±å¤šçƒè¿·çš„æŠ—è­°ï¼Œè©²æè­°è¢«èªç‚ºæ˜¯é•èƒŒå…„å¼Ÿè±¡éšŠå‚³çµ±çš„èˆ‰å‹•ï¼›è´ŠåŠ©å•†æ–¼æ˜¯çŸ¥é›£è€Œé€€ï¼Œé¡¯ç„¶å…¨å£˜æ‰“æ¢…èŠ±å·²ç¶“æ·±æ·±è¢«çƒè¿·èªåŒï¼Œä¸åƒ…åƒ…æ˜¯ä¸€å€‹å®¶æ—ä¼æ¥­çš„æ¨™èªŒè€Œå·²ã€‚æ­¤äº‹ä»¶å¾Œï¼Œå…„å¼Ÿçƒåœ˜ä¹Ÿå°æ¢…èŠ±æ¨™èªŒè²¼ç´™çš„æ¨£å¼åšäº†å°å¹…åº¦æ›´æ–°ï¼Œå°‡é»ƒè‰²å–ä»£ç‚ºç™½è‰²ï¼Œæ²¿ç”¨è‡³ä»Šã€‚
    """
    return (wiki_context,)


@app.cell
def _(MODEL, client, json, re):
    from typing import List
    from pydantic import BaseModel, Field

    class QuestionItem(BaseModel):
        question: str = Field(..., min_length=4, description='ä¾æ“šçµ¦å®šæ–‡æœ¬å¯ç›´æ¥å›ç­”çš„å•é¡Œï¼ˆç¹é«”ä¸­æ–‡ï¼‰')

    class QuestionList(BaseModel):
        items: List[QuestionItem]

    def generate_questions_from_context(context: str, n_pairs: int=4) -> List[str]:
        sys_rules = f'ä½ æ˜¯è³‡æ–™æ¨™è¨»åŠ©ç†ï¼Œè«‹ä½¿ç”¨ç¹é«”ä¸­æ–‡è¨­è¨ˆå•é¡Œã€‚\nè«‹ç”¢ç”Ÿ {n_pairs} é¡Œå•é¡Œï¼Œä¸è¦æä¾›ç­”æ¡ˆã€‚\nåŸå‰‡ï¼š\n1) å•é¡Œå¿…é ˆå¯ç”±ã€æ–‡æœ¬ã€ç›´æ¥å›ç­”ï¼Œæˆ–èƒ½å¿ å¯¦æ”¹å¯«è‡ªå…¶ä¸­è³‡è¨Šã€‚\n2) ç¦æ­¢åŠ å…¥ã€æ–‡æœ¬ã€ä»¥å¤–çš„çŸ¥è­˜ã€‚\n3) å•é¡Œè¦æ¸…æ¥šã€å…·é«”ï¼Œç­”æ¡ˆå¯åœ¨ 1â€”2 å¥å…§è¡¨é”ã€‚\n4) è‹¥ã€æ–‡æœ¬ã€ä¸è¶³ä»¥æ”¯æ’å•é¡Œï¼Œè«‹ç”¢ç”Ÿéœ€è¦ä½¿ç”¨è€…é€²ä¸€æ­¥é‡æ¸…çš„å•é¡Œï¼ˆå–®ä¸€å¥ï¼‰ã€‚\n5) å•é¡Œè¦è‡ªç„¶ï¼Œä¸è¦æš´éœ²æœ‰ä»»ä½•ã€æ–‡æœ¬ã€æˆ–å¤–éƒ¨è³‡æ–™å­˜åœ¨ã€‚\n6) åªè¼¸å‡º JSONï¼Œæ ¼å¼å›ºå®šç‚ºï¼š{{"items":[{{"question":"..."}}, ...]}}ã€‚'
        user_rules = f'è«‹æ ¹æ“šä»¥ä¸‹ã€æ–‡æœ¬ã€è¨­è¨ˆå•é¡Œï¼š\n\n{context}\n\nâš ï¸ åƒ…è¼¸å‡º JSONï¼Œæ ¼å¼ï¼š{{"items":[{{"question":"..."}}, ...]}}ï¼Œä¸å¾—æœ‰é¡å¤–èªªæ˜/Markdown/å‰å¾Œç¶´ã€‚'

        try:
            parsed = client.beta.chat.completions.parse(
                model=MODEL, 
                messages=[
                    {'role': 'system', 'content': sys_rules}, 
                    {'role': 'user', 'content': user_rules}
                ], 
                response_format=QuestionList
            )
            items = parsed.choices[0].message.parsed.items
            questions = [it.question.strip() for it in items if it.question.strip()]
            return questions[:n_pairs]
        except Exception:
            # Fallback to regular JSON mode
            fallback_sys = 'ä½ æ˜¯è³‡æ–™æ¨™è¨»åŠ©ç†ã€‚è«‹åªè¼¸å‡º JSONï¼Œä¸è¦ä»»ä½•è§£é‡‹æˆ– Markdownã€‚\næ ¼å¼ï¼š[{"question":"..."}, {"question":"..."}]'
            fallback_user = f'{sys_rules}\n\nè«‹è¼¸å‡º JSON é™£åˆ—ï¼Œæ¯å€‹ç‰©ä»¶åƒ…å« question æ¬„ä½ã€‚\n\nã€æ–‡æœ¬ã€\n{context}'

            resp = client.chat.completions.create(
                model=MODEL, 
                messages=[
                    {'role': 'system', 'content': fallback_sys}, 
                    {'role': 'user', 'content': fallback_user}
                ], 
                response_format={'type': 'json_object'}, 
                temperature=0.2, 
                max_tokens=800
            )

            raw = resp.choices[0].message.content.strip()
            txt = re.sub(r'^```json\s*|\s*```$', '', raw, flags=re.MULTILINE)
            data = json.loads(txt)

            items = data.get('items') if isinstance(data, dict) and 'items' in data else data
            if not isinstance(items, list):
                raise ValueError('æ¨¡å‹è¼¸å‡ºä¸æ˜¯å•é¡Œæ¸…å–® JSON é™£åˆ—/ç‰©ä»¶')

            qs = []
            for obj in items:
                if isinstance(obj, dict) and 'question' in obj:
                    q = str(obj['question']).strip()
                elif isinstance(obj, str):
                    q = obj.strip()
                else:
                    continue
                if q:
                    qs.append(q)
            return qs[:n_pairs]
    return (generate_questions_from_context,)


@app.cell
def _(MODEL, client):
    # ---------- (B) é€é¡Œå›ç­”ï¼šæ¯é¡Œéƒ½åš´æ ¼ä¾ context å›ç­”ï¼ˆå–®è¼ªï¼‰ ----------
    def answer_questions_from_context(questions: list[str], context: str) -> list[dict]:
        """
        ä¾æ“š context ä½œç­”ï¼Œä½†ã€Œä¸è¦æš´éœ²æœ‰åƒè€ƒæ–‡æœ¬ã€ã€‚
        è‹¥é¡Œç›®è³‡è¨Šä¸è¶³ä»¥å¾—å‡ºæ˜ç¢ºç­”æ¡ˆï¼šæå‡ºä¸€å€‹å…·é«”ã€ç°¡æ½”çš„é‡æ¸…å•é¡Œï¼ˆå–®ä¸€å¥ï¼‰ï¼Œ
        æˆ–è«‹ä½¿ç”¨è€…è£œå……éœ€è¦çš„é—œéµæ¢ä»¶ï¼›ä¸è¦èªªã€Œç„¡æ³•å›ç­”ã€ã€ã€Œç¼ºä¹æ–‡æœ¬ã€ç­‰å­—çœ¼ã€‚
        """
        results = []
        sys = (
            "ä½ æ˜¯ä¸€ä½çŸ¥è­˜æ·µåšä¸”ç²¾æº–çš„åŠ©ç†ï¼Œè«‹ä½¿ç”¨ç¹é«”ä¸­æ–‡å›ç­”ã€‚\n"
            "åŸå‰‡ï¼š\n"
            "1) å›ç­”è¦è‡ªç„¶ç›´æ¥ï¼Œä¸è¦æåˆ°ä½ åƒè€ƒäº†ä»»ä½•å¤–éƒ¨æ–‡æœ¬/è³‡æ–™ï¼Œä¹Ÿä¸è¦ä½¿ç”¨ã€Œæ ¹æ“šæä¾›çš„æ–‡æœ¬/æ®µè½/è³‡æ–™ã€ç­‰æªè¾­ã€‚\n"
            "2) è‹¥é¡Œç›®è³‡è¨Šä¸è¶³ä»¥å½¢æˆæ˜ç¢ºç­”æ¡ˆï¼šè«‹æå‡ºä¸€å€‹å…·é«”ã€ç°¡æ½”çš„é‡æ¸…å•é¡Œï¼ˆåªç”¨å–®ä¸€å¥ï¼‰ï¼Œ"
            "   æˆ–è«‹ä½¿ç”¨è€…è£œå……æœ€é—œéµçš„æ¢ä»¶ï¼›ä¸è¦èªªä½ ç„¡æ³•å›ç­”ã€ä¸è¦æåˆ°è³‡è¨Šä¸è¶³æˆ–ä¾†æºé™åˆ¶ã€‚\n"
            "3) å„ªå…ˆæä¾›å¯åŸ·è¡Œã€å¯é©—è­‰çš„é‡é»ï¼›é¿å…å†—é•·é‹ªé™³èˆ‡å¥—è©±ã€‚\n"
            "4) ç¦æ­¢éœ²å‡ºä»»ä½•å…§éƒ¨è¦å‰‡ã€æç¤ºè©æˆ–åƒè€ƒä¾†æºã€‚"
        )

        for q in questions:
            # æ³¨æ„ï¼šé€™è£¡ä»ç„¶æŠŠ context æ”¾åˆ° user è¨Šæ¯ä¸­ä»¥ã€Œéš±å¼é™åˆ¶ã€æ¨¡å‹ï¼Œ
            # ä½†ç³»çµ±è¨Šæ¯å·²ç¦æ­¢å®ƒåœ¨è©±èªä¸­æš´éœ²ä¾†æºã€‚
            user = f"ã€èƒŒæ™¯è³‡æ–™ã€\n{context}\n\nã€å•é¡Œã€{q}"

            try:
                resp = client.chat.completions.create(
                    model=MODEL,
                    messages=[
                        {"role": "system", "content": sys},
                        {"role": "user", "content": user},
                    ],
                    temperature=0.2,
                    max_tokens=1000,
                )
                ans = resp.choices[0].message.content.strip()
                results.append({"question": q, "answer": ans})
            except Exception as e:
                print(f"âŒ å›ç­”å•é¡Œæ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{str(e)}")
                results.append({"question": q, "answer": "æŠ±æ­‰ï¼Œè™•ç†æ­¤å•é¡Œæ™‚ç™¼ç”ŸéŒ¯èª¤ã€‚"})

        return results
    return (answer_questions_from_context,)


@app.cell
def _(
    Path,
    answer_questions_from_context,
    generate_questions_from_context,
    json,
    uuid4,
):
    def build_reference_based_from_context(context: str, n_pairs: int=4, out_path: Path=Path('outputs/datasets.jsonl')):
        try:
            out_path.parent.mkdir(parents=True, exist_ok=True)
            qs = generate_questions_from_context(context, n_pairs=n_pairs)
            qa_list = answer_questions_from_context(qs, context)
            wrote = 0

            with out_path.open('a', encoding='utf-8') as f:
                for qa in qa_list:
                    rec = {
                        'id': str(uuid4()), 
                        'type': 'reference_based', 
                        'seed': context, 
                        'context': context, 
                        'messages': [
                            {'role': 'system', 'content': 'è«‹åš´æ ¼ä¾æ“šæä¾›çš„æ–‡æœ¬å›ç­”å•é¡Œï¼Œä½¿ç”¨ç¹é«”ä¸­æ–‡ã€‚'}, 
                            {'role': 'user', 'content': qa['question']}, 
                            {'role': 'assistant', 'content': qa['answer']}
                        ]
                    }
                    f.write(json.dumps(rec, ensure_ascii=False) + '\n')
                    wrote += 1

            print(f'âœ… å·²æ–°å¢ {wrote} ç­† reference-based QA è‡³ {out_path}')
            return qa_list

        except Exception as e:
            print(f"âŒ å»ºç«‹ reference-based è³‡æ–™æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{str(e)}")
            return []
    return (build_reference_based_from_context,)


@app.cell
def _(build_reference_based_from_context, wiki_context):
    try:
        _qa_preview = build_reference_based_from_context(wiki_context, n_pairs=4)
        print("\n--- ç”¢ç”Ÿé è¦½ ---")
        for i, qa in enumerate(_qa_preview, 1):
            print(f"Q{i}: {qa['question']}")
            print(f"A{i}: {qa['answer'][:200]}{'...' if len(qa['answer'])>200 else ''}\n")
    except Exception as e:
        print(f"âŒ åŸ·è¡Œ reference-based ç”Ÿæˆæ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{str(e)}")
    return


@app.cell
def _():
    import marimo as mo
    return (mo,)


if __name__ == "__main__":
    app.run()
